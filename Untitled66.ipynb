{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl6FjLJr6pQA",
        "outputId": "e6aa6d44-5c70-4ce8-e9d4-3477baa96f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-06 02:12:09--  https://doc-04-94-docs.googleusercontent.com/docs/securesc/1l3ul9726mftuj85bnpea3lnean3t71f/kn4igcgfi55ivori92gpqtfg6msefkhd/1646532600000/15187745062133414559/03167207420045571302/148M_4LvHyb0J_sNWxrFSYjv3lO5ACigK?e=download&ax=ACxEAsbV8Jhib0yrhSKgDPAEycK0-9JyBfi9LVd2_e-1TPYi3Pw720t9Kgsm6ouata2OTp1_u6Z3CZYUjoSf1SnWR1LpCySYfGXDcU2UeW_eZH-rxrX-sTRnNgVE4fA3a_MBXZbuLzK7c2cMK9AW4DQFCjdj0SQT-fLLejo3PeQRbZnyb3cVA-6D4dlZ96RqwZAmErw3u9sddAaw3i4gdu3fXbHEVsbHWQWEckEB4kKPRbptebGWk7ocEc8O7E5PuFKklKDs8ldVUXTnuMCrVRZkrX0jYGHZyolaIY4L1rtLUeW53CLrz2oCp6U-6s68i-P2Q3sw17s_Vmx0kUYuDWbWoTFNDIj5LRaCr3_YoKKVkofqFhmxaX46F8ZimleJgrGtvujzWAo7RACOoRuB_VikgCez542_5__lz2GWRZVylkgZIil9uxF0dGFvjzWpPT1gue2RzWWzy6XLnsMg-LygOR2bYFtigSFaCw90Ich8FpNRQpXkBUsGetDb4C6nuxxcO6qWFuQOGnPjK40Uks4URwGsg02ecdn-IhAncA-PxyAFmhnGs0oh2Zen-rI8SBnKBLmh1uZnC1E50Ih7WOeM9vTcvnTRA2pbY8g823LK2yJ-2V0xSju9ukWIH2jk3TZP8h2LvCqFIaq1cbLiXCG-OwRj5MrUwUaGs2kRXCZi&authuser=0&nonce=71ocj53s01snq&user=03167207420045571302&hash=aneg9f8n7g8mqr3g8p3q55klceu6t0lq\n",
            "Resolving doc-04-94-docs.googleusercontent.com (doc-04-94-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n",
            "Connecting to doc-04-94-docs.googleusercontent.com (doc-04-94-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34008151 (32M) [application/x-gzip]\n",
            "Saving to: ‘lang8.bea19.tar.gz’\n",
            "\n",
            "lang8.bea19.tar.gz  100%[===================>]  32.43M  70.9MB/s    in 0.5s    \n",
            "\n",
            "2022-03-06 02:12:09 (70.9 MB/s) - ‘lang8.bea19.tar.gz’ saved [34008151/34008151]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --header=\"Host: doc-04-94-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Cookie: AUTH_glh8fmi9goppngvb244pvfpmluc342mq_nonce=71ocj53s01snq\" --header=\"Connection: keep-alive\" \"https://doc-04-94-docs.googleusercontent.com/docs/securesc/1l3ul9726mftuj85bnpea3lnean3t71f/kn4igcgfi55ivori92gpqtfg6msefkhd/1646532600000/15187745062133414559/03167207420045571302/148M_4LvHyb0J_sNWxrFSYjv3lO5ACigK?e=download&ax=ACxEAsbV8Jhib0yrhSKgDPAEycK0-9JyBfi9LVd2_e-1TPYi3Pw720t9Kgsm6ouata2OTp1_u6Z3CZYUjoSf1SnWR1LpCySYfGXDcU2UeW_eZH-rxrX-sTRnNgVE4fA3a_MBXZbuLzK7c2cMK9AW4DQFCjdj0SQT-fLLejo3PeQRbZnyb3cVA-6D4dlZ96RqwZAmErw3u9sddAaw3i4gdu3fXbHEVsbHWQWEckEB4kKPRbptebGWk7ocEc8O7E5PuFKklKDs8ldVUXTnuMCrVRZkrX0jYGHZyolaIY4L1rtLUeW53CLrz2oCp6U-6s68i-P2Q3sw17s_Vmx0kUYuDWbWoTFNDIj5LRaCr3_YoKKVkofqFhmxaX46F8ZimleJgrGtvujzWAo7RACOoRuB_VikgCez542_5__lz2GWRZVylkgZIil9uxF0dGFvjzWpPT1gue2RzWWzy6XLnsMg-LygOR2bYFtigSFaCw90Ich8FpNRQpXkBUsGetDb4C6nuxxcO6qWFuQOGnPjK40Uks4URwGsg02ecdn-IhAncA-PxyAFmhnGs0oh2Zen-rI8SBnKBLmh1uZnC1E50Ih7WOeM9vTcvnTRA2pbY8g823LK2yJ-2V0xSju9ukWIH2jk3TZP8h2LvCqFIaq1cbLiXCG-OwRj5MrUwUaGs2kRXCZi&authuser=0&nonce=71ocj53s01snq&user=03167207420045571302&hash=aneg9f8n7g8mqr3g8p3q55klceu6t0lq\" -c -O 'lang8.bea19.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MXBteOe3olv",
        "outputId": "b841f48f-5332-4bc6-d908-1ac1f0aebc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-06 02:12:11--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
            "--2022-03-06 02:12:11--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucfc021a63d066b741a498b8dab3.dl.dropboxusercontent.com/cd/0/inline/Bg4ildiHUr9ymI3MMciCKcd3O7ifF90hm8WXpDaSDdKPcmuZ4WQCzXuEdswP1O6KI1a11r6gSm7NrKxmFqx9Hr1t8dFHp7Xr9nVKEmMajIFPUwHvs_F9MrwlV0VyrRX7_-30ApdWvxYUPi7AbOvCUNHe/file# [following]\n",
            "--2022-03-06 02:12:11--  https://ucfc021a63d066b741a498b8dab3.dl.dropboxusercontent.com/cd/0/inline/Bg4ildiHUr9ymI3MMciCKcd3O7ifF90hm8WXpDaSDdKPcmuZ4WQCzXuEdswP1O6KI1a11r6gSm7NrKxmFqx9Hr1t8dFHp7Xr9nVKEmMajIFPUwHvs_F9MrwlV0VyrRX7_-30ApdWvxYUPi7AbOvCUNHe/file\n",
            "Resolving ucfc021a63d066b741a498b8dab3.dl.dropboxusercontent.com (ucfc021a63d066b741a498b8dab3.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucfc021a63d066b741a498b8dab3.dl.dropboxusercontent.com (ucfc021a63d066b741a498b8dab3.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘glove.6B.100d.txt’\n",
            "\n",
            "glove.6B.100d.txt   100%[===================>] 331.04M  95.3MB/s    in 3.4s    \n",
            "\n",
            "2022-03-06 02:12:15 (96.0 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q4b9s84AAUm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtJGgMny6qbT",
        "outputId": "d96f9c0a-4889-4081-b646-ffb52e557c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lang8.train.auto.bea19.m2\n",
            "lang8_to_m2.py\n",
            "readme.txt\n"
          ]
        }
      ],
      "source": [
        "!tar -xzvf \"/content/lang8.bea19.tar.gz\"\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek0wHSzM9ntr",
        "outputId": "af5e9791-374b-4500-d9f7-81ac475bed79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scripts\n",
            "  Downloading scripts-2.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting stua\n",
            "  Downloading stua-0.2-py2.py3-none-any.whl (8.2 kB)\n",
            "Installing collected packages: stua, scripts\n",
            "Successfully installed scripts-2.0 stua-0.2\n"
          ]
        }
      ],
      "source": [
        "pip install scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjxoEDDP9uai"
      },
      "outputs": [],
      "source": [
        "import scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgQBZ6H28Ujq"
      },
      "outputs": [],
      "source": [
        "with open('lang8.train.auto.bea19.m2') as f: #lang8.train.auto.bea19.m2\n",
        "  data = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E0fXht_8jG_"
      },
      "outputs": [],
      "source": [
        "#Reference: https://github.com/mridul1012/Grammatical-Error-Correction-with-Neural-Networks\n",
        "#https://www.cl.cam.ac.uk/research/nl/bea2019st/data/corr_from_m2.py\n",
        "\n",
        "# Apply the edits of a single annotator to generate the corrected sentences.\n",
        "m2 = open('lang8.train.auto.bea19.m2').read().strip().split(\"\\n\\n\")\n",
        "out = open('corrected.txt', \"w\")\n",
        "in_ = open('error.txt', \"w\")\n",
        "# Do not apply edits with these error types\n",
        "skip = {\"noop\", \"UNK\", \"Um\"}\n",
        "\n",
        "for sent in (m2):\n",
        "  #print(sent)\n",
        "  sent = sent.split(\"\\n\")\n",
        "  cor_sent = sent[0].split()[1:] # Ignore \"S \"\n",
        "\n",
        "  in_.write(\" \".join(sent[0].split()[1:])+\"\\n\" )\n",
        "  #print('ORIGINAL',sent[0].split()[1:])\n",
        "  \n",
        "  edits = sent[1:]\n",
        "  offset = 0\n",
        "  for edit in edits:\n",
        "    edit = edit.split(\"|||\")\n",
        "    if edit[1] in skip: continue # Ignore certain edits\n",
        "    coder = int(edit[-1])\n",
        "    if coder != 0: continue # Ignore other coders\n",
        "    span = edit[0].split()[1:] # Ignore \"A \"\n",
        "    start = int(span[0])\n",
        "    end = int(span[1])\n",
        "    cor = edit[2].split()\n",
        "    cor_sent[start+offset:end+offset] = cor\n",
        "    offset = offset-(end-start)+len(cor)\n",
        "\n",
        "  #print('CORRECT',cor_sent)\n",
        "  out.write(\" \".join(cor_sent)+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fdfel5uj-gkv"
      },
      "outputs": [],
      "source": [
        "with open('corrected.txt') as f:\n",
        "  correct_data = f.read()\n",
        "\n",
        "with open('error.txt') as f:\n",
        "  error_data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdMf7zNh-6Dj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agDY_UOy-it_"
      },
      "outputs": [],
      "source": [
        "final_data = pd.DataFrame(columns = ['error', 'correct'])\n",
        "\n",
        "final_data['correct'] = correct_data.split('\\n')\n",
        "final_data['error'] = error_data.split('\\n')[:len(final_data['correct'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeyYP-QK-kAH",
        "outputId": "14379e01-0b7e-4853-9520-df494da96091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                        Good luck on your new start !\n",
              "1      My teacher is going to move to change his job .\n",
              "2    He is a so nice guy and taught me English very...\n",
              "3     And he took in my favorite subject like soccer .\n",
              "4    Actually , who let me know about Lang - 8 was ...\n",
              "5    He is also good at Japanese and studies ' Kanj...\n",
              "6        His Kanji 's ability is much better than me .\n",
              "7    We 've known each other for only half a year ,...\n",
              "8    I 'm going to miss him but I really wish him t...\n",
              "9    I 'm looking forward to seeing him again throu...\n",
              "Name: error, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "final_data['error'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPQqpWAh_QLy",
        "outputId": "0d574549-ae15-4be1-c083-09f7f6503b37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                        Good luck on your new start !\n",
              "1      My teacher is going to move to change his job .\n",
              "2    He is a so nice guy and taught me English very...\n",
              "3    And he took in my favorite subjects like soccer .\n",
              "4    Actually , he was the one who let me know abou...\n",
              "5    He is also good at Japanese and studies ' Kanj...\n",
              "6         His Kanji ability is much better than mine .\n",
              "7    We 've known each other for only half a year ,...\n",
              "8    I 'm going to miss him but I really wish him t...\n",
              "9    I 'm looking forward to seeing him again throu...\n",
              "Name: correct, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "final_data['correct'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QetbRzX__c3K"
      },
      "outputs": [],
      "source": [
        "data = final_data[:20000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "lzW_C9sd0IWl",
        "outputId": "8a34165b-fb87-4a6f-ece1-3d475bbf6dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2a032778-cade-495a-b2d0-9b6fcc57c0f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>error</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good luck on your new start</td>\n",
              "      <td>good luck on your new start</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>my teacher is going to move to change his job</td>\n",
              "      <td>my teacher is going to move to change his job</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he is a so nice guy and taught me english very...</td>\n",
              "      <td>he is a so nice guy and taught me english very...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>and he took in my favorite subject like soccer</td>\n",
              "      <td>and he took in my favorite subjects like soccer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>actually  who let me know about lang  8 was him</td>\n",
              "      <td>actually  he was the one who let me know about...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a032778-cade-495a-b2d0-9b6fcc57c0f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a032778-cade-495a-b2d0-9b6fcc57c0f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a032778-cade-495a-b2d0-9b6fcc57c0f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               error  \\\n",
              "0                       good luck on your new start    \n",
              "1     my teacher is going to move to change his job    \n",
              "2  he is a so nice guy and taught me english very...   \n",
              "3    and he took in my favorite subject like soccer    \n",
              "4   actually  who let me know about lang  8 was him    \n",
              "\n",
              "                                             correct  \n",
              "0                       good luck on your new start   \n",
              "1     my teacher is going to move to change his job   \n",
              "2  he is a so nice guy and taught me english very...  \n",
              "3   and he took in my favorite subjects like soccer   \n",
              "4  actually  he was the one who let me know about...  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import re\n",
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['error'] = data['error'].apply(preprocess)\n",
        "data['correct'] = data['correct'].apply(preprocess_ita)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BmF54-t0c2P"
      },
      "outputs": [],
      "source": [
        "err_lengths = data['error'].str.split().apply(len)\n",
        "cor_lengths = data['correct'].str.split().apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOa92AOK0c6J",
        "outputId": "2f512917-3ef3-4374-b96e-27252d9a6644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.0\n",
            "10 3.0\n",
            "20 4.0\n",
            "30 6.0\n",
            "40 7.0\n",
            "50 9.0\n",
            "60 10.0\n",
            "70 12.0\n",
            "80 14.0\n",
            "90 18.0\n",
            "100 86.0\n",
            "90 18.0\n",
            "91 19.0\n",
            "92 20.0\n",
            "93 21.0\n",
            "94 22.0\n",
            "95 23.0\n",
            "96 24.0\n",
            "97 26.0\n",
            "98 28.0\n",
            "99 34.0\n",
            "100 86.0\n",
            "99.1 34.0\n",
            "99.2 35.0\n",
            "99.3 36.0\n",
            "99.4 37.0\n",
            "99.5 38.0\n",
            "99.6 40.0\n",
            "99.7 42.00300000000061\n",
            "99.8 46.00200000000041\n",
            "99.9 53.0\n",
            "100 86.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(err_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(err_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(err_lengths, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjoKbkWm0c9F"
      },
      "outputs": [],
      "source": [
        "#err = 35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q1sYWHD0dB3",
        "outputId": "6bed8489-efa7-48cf-e485-ca6ec34898aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.0\n",
            "10 3.0\n",
            "20 5.0\n",
            "30 6.0\n",
            "40 7.0\n",
            "50 9.0\n",
            "60 10.0\n",
            "70 12.0\n",
            "80 15.0\n",
            "90 19.0\n",
            "100 90.0\n",
            "90 19.0\n",
            "91 20.0\n",
            "92 20.0\n",
            "93 21.0\n",
            "94 22.0\n",
            "95 23.0\n",
            "96 25.0\n",
            "97 27.0\n",
            "98 29.0\n",
            "99 34.0\n",
            "100 90.0\n",
            "99.1 35.0\n",
            "99.2 36.0\n",
            "99.3 37.0\n",
            "99.4 38.0\n",
            "99.5 40.0\n",
            "99.6 41.0\n",
            "99.7 44.0\n",
            "99.8 50.0\n",
            "99.9 55.00100000000384\n",
            "100 90.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(cor_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(cor_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(cor_lengths, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8yyPbDB0dEe",
        "outputId": "cd5572cd-f286-4e4c-9a3d-0134fdbf4c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "data['err_len'] = data['error'].str.split().apply(len)\n",
        "data = data[data['err_len'] < 35]\n",
        "\n",
        "data['cor_len'] = data['correct'].str.split().apply(len)\n",
        "data = data[data['cor_len'] < 35]\n",
        "\n",
        "data['cor_inp'] = '<start> ' + data['correct'].astype(str)\n",
        "data['cor_out'] = data['correct'].astype(str) + ' <end>'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Nv_AM0Y52uyb",
        "outputId": "7b59be20-5a06-4b5e-b986-e37793e8ae37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-532e673a-f825-41c1-80a7-257b769387ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>error</th>\n",
              "      <th>cor_inp</th>\n",
              "      <th>cor_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good luck on your new start</td>\n",
              "      <td>&lt;start&gt; good luck on your new start</td>\n",
              "      <td>good luck on your new start  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>my teacher is going to move to change his job</td>\n",
              "      <td>&lt;start&gt; my teacher is going to move to change ...</td>\n",
              "      <td>my teacher is going to move to change his job ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he is a so nice guy and taught me english very...</td>\n",
              "      <td>&lt;start&gt; he is a so nice guy and taught me engl...</td>\n",
              "      <td>he is a so nice guy and taught me english very...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>and he took in my favorite subject like soccer</td>\n",
              "      <td>&lt;start&gt; and he took in my favorite subjects li...</td>\n",
              "      <td>and he took in my favorite subjects like socce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>actually  who let me know about lang  8 was him</td>\n",
              "      <td>&lt;start&gt; actually  he was the one who let me kn...</td>\n",
              "      <td>actually  he was the one who let me know about...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-532e673a-f825-41c1-80a7-257b769387ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-532e673a-f825-41c1-80a7-257b769387ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-532e673a-f825-41c1-80a7-257b769387ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               error  \\\n",
              "0                       good luck on your new start    \n",
              "1     my teacher is going to move to change his job    \n",
              "2  he is a so nice guy and taught me english very...   \n",
              "3    and he took in my favorite subject like soccer    \n",
              "4   actually  who let me know about lang  8 was him    \n",
              "\n",
              "                                             cor_inp  \\\n",
              "0               <start> good luck on your new start    \n",
              "1  <start> my teacher is going to move to change ...   \n",
              "2  <start> he is a so nice guy and taught me engl...   \n",
              "3  <start> and he took in my favorite subjects li...   \n",
              "4  <start> actually  he was the one who let me kn...   \n",
              "\n",
              "                                             cor_out  \n",
              "0                 good luck on your new start  <end>  \n",
              "1  my teacher is going to move to change his job ...  \n",
              "2  he is a so nice guy and taught me english very...  \n",
              "3  and he took in my favorite subjects like socce...  \n",
              "4  actually  he was the one who let me know about...  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data = data.drop(['correct','err_len','cor_len'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkzvZU_H0dG_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hocnZin50dJ5",
        "outputId": "9a3875f1-1fd6-40cc-d0da-c712245e4fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15832, 3) (3958, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train.shape, validation.shape)\n",
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['cor_inp']= str(train.iloc[0]['cor_inp'])+' <end>'\n",
        "train.iloc[0]['cor_out']= str(train.iloc[0]['cor_out'])+' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "G7QR5bWH2UN8",
        "outputId": "f5f7f643-5fe0-4f8d-c672-6325a0b73cfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fc285c10-1d27-4709-9320-484336b32fc2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>error</th>\n",
              "      <th>cor_inp</th>\n",
              "      <th>cor_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13851</th>\n",
              "      <td>i respect the people who can use them freely</td>\n",
              "      <td>&lt;start&gt; i respect the people who can use them ...</td>\n",
              "      <td>i respect the people who can use them freely  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16673</th>\n",
              "      <td>in the summer  what your favourite fruit</td>\n",
              "      <td>&lt;start&gt; in summer  what is your favourite fruit</td>\n",
              "      <td>in summer  what is your favourite fruit  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17517</th>\n",
              "      <td>hi i  am a new menber</td>\n",
              "      <td>&lt;start&gt; hi i  am a new member</td>\n",
              "      <td>hi i  am a new member &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2359</th>\n",
              "      <td>it is raining right now</td>\n",
              "      <td>&lt;start&gt; it is raining right now</td>\n",
              "      <td>it is raining right now  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15073</th>\n",
              "      <td>i have  not came across this slump for that lo...</td>\n",
              "      <td>&lt;start&gt; i have  not came across this slump for...</td>\n",
              "      <td>i have  not came across this slump for a long ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc285c10-1d27-4709-9320-484336b32fc2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc285c10-1d27-4709-9320-484336b32fc2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc285c10-1d27-4709-9320-484336b32fc2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   error  \\\n",
              "13851      i respect the people who can use them freely    \n",
              "16673          in the summer  what your favourite fruit    \n",
              "17517                              hi i  am a new menber   \n",
              "2359                            it is raining right now    \n",
              "15073  i have  not came across this slump for that lo...   \n",
              "\n",
              "                                                 cor_inp  \\\n",
              "13851  <start> i respect the people who can use them ...   \n",
              "16673   <start> in summer  what is your favourite fruit    \n",
              "17517                      <start> hi i  am a new member   \n",
              "2359                    <start> it is raining right now    \n",
              "15073  <start> i have  not came across this slump for...   \n",
              "\n",
              "                                                 cor_out  \n",
              "13851  i respect the people who can use them freely  ...  \n",
              "16673     in summer  what is your favourite fruit  <end>  \n",
              "17517                        hi i  am a new member <end>  \n",
              "2359                      it is raining right now  <end>  \n",
              "15073  i have  not came across this slump for a long ...  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "hTxrh9so2cbc",
        "outputId": "19671eec-05ef-4995-bdff-219200caa296"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-37b3ddb9-0ff6-441c-b3c4-de3f061d7e2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>error</th>\n",
              "      <th>cor_inp</th>\n",
              "      <th>cor_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>wake up</td>\n",
              "      <td>&lt;start&gt; wake up</td>\n",
              "      <td>wake up  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8144</th>\n",
              "      <td>maybe the autumn has becomed</td>\n",
              "      <td>&lt;start&gt; maybe autumn is coming</td>\n",
              "      <td>maybe autumn is coming  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19831</th>\n",
              "      <td>thank you</td>\n",
              "      <td>&lt;start&gt; thank you</td>\n",
              "      <td>thank you &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>so i wanted to work part  time at usj  too</td>\n",
              "      <td>&lt;start&gt; so i wanted to work part   time at usj...</td>\n",
              "      <td>so i wanted to work part   time at usj  too  &lt;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>but i really enjoy reading   not only books  b...</td>\n",
              "      <td>&lt;start&gt; but i really enjoy reading   not only ...</td>\n",
              "      <td>but i really enjoy reading   not only books  b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37b3ddb9-0ff6-441c-b3c4-de3f061d7e2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37b3ddb9-0ff6-441c-b3c4-de3f061d7e2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37b3ddb9-0ff6-441c-b3c4-de3f061d7e2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   error  \\\n",
              "249                                             wake up    \n",
              "8144                       maybe the autumn has becomed    \n",
              "19831                                          thank you   \n",
              "396          so i wanted to work part  time at usj  too    \n",
              "962    but i really enjoy reading   not only books  b...   \n",
              "\n",
              "                                                 cor_inp  \\\n",
              "249                                     <start> wake up    \n",
              "8144                     <start> maybe autumn is coming    \n",
              "19831                                  <start> thank you   \n",
              "396    <start> so i wanted to work part   time at usj...   \n",
              "962    <start> but i really enjoy reading   not only ...   \n",
              "\n",
              "                                                 cor_out  \n",
              "249                                       wake up  <end>  \n",
              "8144                       maybe autumn is coming  <end>  \n",
              "19831                                    thank you <end>  \n",
              "396    so i wanted to work part   time at usj  too  <...  \n",
              "962    but i really enjoy reading   not only books  b...  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "validation.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISqRDSPS2ceb"
      },
      "outputs": [],
      "source": [
        "err_lengths = train['error'].str.split().apply(len)\n",
        "corr_lengths = train['cor_inp'].str.split().apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9liJE_2a2cg2"
      },
      "outputs": [],
      "source": [
        "tknizer_err = Tokenizer()\n",
        "tknizer_err.fit_on_texts(train['error'].values)\n",
        "tknizer_cor = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_cor.fit_on_texts(train['cor_inp'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFVL80Tl2clb",
        "outputId": "21986fa6-1872-40b3-bbc8-e14afea09828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9981\n",
            "10573\n"
          ]
        }
      ],
      "source": [
        "vocab_size_cor=len(tknizer_cor.word_index.keys())\n",
        "print(vocab_size_cor)\n",
        "vocab_size_err=len(tknizer_err.word_index.keys())\n",
        "print(vocab_size_err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F53LLNXo2cn3",
        "outputId": "6937ce28-3b33-4b17-a994-b59e2f185893"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 5197)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "tknizer_cor.word_index['<start>'], tknizer_cor.word_index['<end>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpEbB_mW2cpv"
      },
      "outputs": [],
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_cor+1, 100))\n",
        "for word, i in tknizer_cor.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l16IYl77uJz",
        "outputId": "fba05b40-b19f-4333-f438-0e553fbdc939"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9982, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XaPvcw12csX"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['error'].values\n",
        "        self.decoder_inps = data['cor_inp'].values\n",
        "        self.decoder_outs = data['cor_out'].values\n",
        "        self.tknizer_eng = tknizer_cor\n",
        "        self.tknizer_ita = tknizer_err\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pWpqsHD7NZI",
        "outputId": "b30e67c4-8674-4683-ddfc-70d05ece0582"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7f8743447f90>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "tknizer_cor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_zb8Fjn2cxg",
        "outputId": "d54b318e-3678-4c01-8016-430ce5149c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 35) (512, 35) (512, 35)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(train, tknizer_err, tknizer_cor, 35)\n",
        "test_dataset  = Dataset(validation, tknizer_err, tknizer_cor, 35)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=512)\n",
        "\n",
        "\n",
        "print(test_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "      super().__init__()\n",
        "      self.inp_vocab_size= inp_vocab_size\n",
        "      self.embedding_size = embedding_size\n",
        "      self.input_length = input_length\n",
        "      self.lstm_size = lstm_size\n",
        "      self.lstm_output = 0\n",
        "      self.lstm_state_h = 0\n",
        "      self.lstm_state_c = 0\n",
        "      self.embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                            mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "      self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "      input_embedd= self.embedding(input_sequence)\n",
        "      self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
        "      return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      #check\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      initial_hidden_state =tf.zeros(shape=[batch_size,self.lstm_size],dtype=tf.int32)\n",
        "      initial_cell_state =tf.zeros(shape=[batch_size,self.lstm_size],dtype=tf.int32)\n",
        "      return initial_hidden_state,initial_cell_state"
      ],
      "metadata": {
        "id": "FPhIAxGVBnWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super().__init__()\n",
        "    self.scoring_function = scoring_function\n",
        "    self.att_units = att_units\n",
        "\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "\n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      # encoder output\n",
        "      self.Dot = tf.keras.layers.Dot(axes=(1, 2))\n",
        "    if scoring_function == 'general':\n",
        "      self.W1= tf.keras.layers.Dense(att_units)\n",
        "      self.Dot = tf.keras.layers.Dot(axes=(1, 2))\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "        self.W2 = tf.keras.layers.Dense(att_units)\n",
        "        self.W3 = tf.keras.layers.Dense(att_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "    if self.scoring_function == 'dot':\n",
        "        # Implement Dot score function here\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state,1)\n",
        "        dhs = tf.transpose(decoder_hidden_state,(0,2,1))\n",
        "        #print(dhs.shape)\n",
        "        #print(encoder_output.shape)\n",
        "        x = self.Dot([dhs,encoder_output])\n",
        "        a = tf.nn.softmax(tf.transpose(x,(0,2,1)),axis=1)\n",
        "        c = a*encoder_output\n",
        "        c = tf.reduce_sum(c,axis = 1)\n",
        "        #print(c.shape,a.shape)\n",
        "        return c,a\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state,1)\n",
        "        wa = self.W1(encoder_output)\n",
        "        dhs = tf.transpose(decoder_hidden_state,(0,2,1))\n",
        "        x = self.Dot([dhs,wa])\n",
        "        \n",
        "        a = tf.nn.softmax(tf.transpose(x,(0,2,1)),axis=1)\n",
        "        c = a*encoder_output\n",
        "        c = tf.reduce_sum(c,axis = 1)\n",
        "        #print(c.shape,a.shape)\n",
        "        return c,a\n",
        "\n",
        "    elif self.scoring_function == 'concat':\n",
        "        # Implement General score function here\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state,1)\n",
        "        e = self.V(tf.nn.tanh(self.W2(decoder_hidden_state)+self.W3(encoder_output)))\n",
        "        a = tf.nn.softmax(e,axis = 1)\n",
        "        c = a*encoder_output\n",
        "        c = tf.reduce_sum(c,axis = 1)\n",
        "        m = self.W2\n",
        "        #print(c.shape,a.shape)\n",
        "        #print(m.shape)\n",
        "        return c,a"
      ],
      "metadata": {
        "id": "kBBx0EofBnbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "    super().__init__()\n",
        "    self.tar_vocab_size = tar_vocab_size \n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.input_length =  input_length\n",
        "    self.dec_units = dec_units\n",
        "    self.score_fun = score_fun\n",
        "    self.att_units = att_units\n",
        "# Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "    self.lstm_output = 0\n",
        "    self.lstm_state_h = 0\n",
        "    self.lstm_state_c = 0\n",
        "    self.embedding = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                            mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "    self.lstm = LSTM(att_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "    self.dense   = Dense(self.tar_vocab_size)\n",
        "    self.attention = Attention(scoring_function = self.score_fun,att_units = self.att_units)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "    \n",
        "    input_embedding= self.embedding(input_to_decoder)\n",
        "    context,similarities = self.attention(state_h,encoder_output)\n",
        "    #print(input_embedding.shape)\n",
        "    #print(context.shape)\n",
        "    concat = tf.keras.layers.Concatenate(axis = 2)([input_embedding,tf.expand_dims(context,1)])\n",
        "    decoder_output,*states = self.lstm(concat)\n",
        "    \n",
        "    #print(states[0].shape)\n",
        "    decoder_hidden,decoder_cell = states[0],states[1]\n",
        "\n",
        "    output =self.dense(decoder_output[:,:,:self.dec_units])\n",
        "    #print(decoder_hidden.shape)\n",
        "    return tf.squeeze(output,axis = 1),decoder_hidden,decoder_cell,similarities,context\n",
        "#context_vector = 32116\n",
        "#i2d_output = 32112"
      ],
      "metadata": {
        "id": "3wtpeDFWBngR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "                \n",
        "      super().__init__()\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      self.out_vocab_size = out_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "      self.onestepdecoder=One_Step_Decoder(self.out_vocab_size, self.embedding_dim, self.input_length, self.dec_units ,self.score_fun ,self.att_units)  \n",
        "\n",
        "        \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        \n",
        "        #Iterate till the length of the decoder input\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "        # Return the tensor array\n",
        "        all_outputs = tf.TensorArray(tf.float32, size=35, name = 'output_arrays',dynamic_size = True,clear_after_read = False)\n",
        "        for i in range(35):\n",
        "          output,decoder_hidden_state ,decoder_cell_state,attention_weights,context_vector = self.onestepdecoder(input_to_decoder[:,i:i+1],encoder_output,decoder_hidden_state,decoder_cell_state)#sequence is correct\n",
        "          all_outputs = all_outputs.write(i,output)\n",
        "\n",
        "       # all_outputs.mark_used()\n",
        "\n",
        "\n",
        "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
        "        return all_outputs"
      ],
      "metadata": {
        "id": "NBFTQ-paBnjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self,encoder_inputs_length,decoder_inputs_length,output_vocab_size,batch_size):\n",
        "    #Intialize objects from encoder decoder\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(inp_vocab_size = vocab_size_err+2,embedding_size = 100,lstm_size = 128,input_length = encoder_inputs_length)\n",
        "    self.decoder = Decoder(out_vocab_size = vocab_size_cor+2,embedding_dim = 100,input_length = decoder_inputs_length ,dec_units = 128,score_fun = 'concat',att_units = 128)\n",
        "    self.dense   = Dense(output_vocab_size, activation='softmax')\n",
        "    self.batch_size = batch_size\n",
        "    self.embedding = Embedding(input_dim=vocab_size_cor+1, output_dim=100, input_length=35,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "\n",
        "  \n",
        "  def call(self,data):\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    # return the decoder output\n",
        "    input,output = data[0],data[1]\n",
        "    initial_state = self.encoder.initialize_states(self.batch_size)\n",
        "    input_embedd= input\n",
        "    encoder_output,encoder_h,encoder_c = self.encoder(input_embedd,initial_state)\n",
        "    decoder_output = self.decoder(output,encoder_output,encoder_h,encoder_c)\n",
        "    return decoder_output\n",
        "   "
      ],
      "metadata": {
        "id": "gZBeD07WBnmG"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u4aCBYEtW7si"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "FhnDFUlMBnpJ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(train, tknizer_err, tknizer_cor, 35)\n",
        "test_dataset  = Dataset(validation, tknizer_err, tknizer_cor, 35)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=256)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size = 256)\n",
        "model  = encoder_decoder(encoder_inputs_length=35,decoder_inputs_length=35,output_vocab_size=vocab_size_cor,batch_size =1)\n",
        "optimizer = tf.keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=optimizer,loss=loss_function)\n",
        "train_steps=train.shape[0]//256\n",
        "valid_steps=validation.shape[0]//256\n",
        "history= model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs= 100 , validation_data=test_dataloader, validation_steps=valid_steps)\n",
        "model.summary()\n",
        "#change the word embedding introduce 300"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI3WBVOrD6JV",
        "outputId": "172cbb45-2101-43e3-c77b-b3667f778ace"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "61/61 [==============================] - 258s 1s/step - loss: 2.0970 - val_loss: 1.7999\n",
            "Epoch 2/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 1.8810 - val_loss: 1.7612\n",
            "Epoch 3/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 1.8475 - val_loss: 1.7392\n",
            "Epoch 4/100\n",
            "61/61 [==============================] - 29s 468ms/step - loss: 1.8170 - val_loss: 1.7146\n",
            "Epoch 5/100\n",
            "61/61 [==============================] - 29s 468ms/step - loss: 1.7892 - val_loss: 1.6872\n",
            "Epoch 6/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 1.7550 - val_loss: 1.6573\n",
            "Epoch 7/100\n",
            "61/61 [==============================] - 28s 467ms/step - loss: 1.7184 - val_loss: 1.6264\n",
            "Epoch 8/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 1.6844 - val_loss: 1.6008\n",
            "Epoch 9/100\n",
            "61/61 [==============================] - 29s 467ms/step - loss: 1.6521 - val_loss: 1.5808\n",
            "Epoch 10/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 1.6213 - val_loss: 1.5546\n",
            "Epoch 11/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 1.5931 - val_loss: 1.5348\n",
            "Epoch 12/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 1.5670 - val_loss: 1.5182\n",
            "Epoch 13/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 1.5426 - val_loss: 1.5023\n",
            "Epoch 14/100\n",
            "61/61 [==============================] - 29s 470ms/step - loss: 1.5189 - val_loss: 1.4806\n",
            "Epoch 15/100\n",
            "61/61 [==============================] - 29s 469ms/step - loss: 1.4944 - val_loss: 1.4615\n",
            "Epoch 16/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 1.4694 - val_loss: 1.4427\n",
            "Epoch 17/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 1.4421 - val_loss: 1.4195\n",
            "Epoch 18/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 1.4144 - val_loss: 1.3987\n",
            "Epoch 19/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 1.3855 - val_loss: 1.3757\n",
            "Epoch 20/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 1.3579 - val_loss: 1.3531\n",
            "Epoch 21/100\n",
            "61/61 [==============================] - 28s 462ms/step - loss: 1.3305 - val_loss: 1.3356\n",
            "Epoch 22/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 1.3012 - val_loss: 1.3192\n",
            "Epoch 23/100\n",
            "61/61 [==============================] - 28s 461ms/step - loss: 1.2718 - val_loss: 1.2842\n",
            "Epoch 24/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 1.2414 - val_loss: 1.2598\n",
            "Epoch 25/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 1.2111 - val_loss: 1.2330\n",
            "Epoch 26/100\n",
            "61/61 [==============================] - 28s 467ms/step - loss: 1.1795 - val_loss: 1.2069\n",
            "Epoch 27/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 1.1478 - val_loss: 1.1833\n",
            "Epoch 28/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 1.1134 - val_loss: 1.1825\n",
            "Epoch 29/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 1.0826 - val_loss: 1.1278\n",
            "Epoch 30/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 1.0481 - val_loss: 1.1024\n",
            "Epoch 31/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 1.0164 - val_loss: 1.0793\n",
            "Epoch 32/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.9840 - val_loss: 1.0512\n",
            "Epoch 33/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.9539 - val_loss: 1.0343\n",
            "Epoch 34/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 0.9257 - val_loss: 1.0360\n",
            "Epoch 35/100\n",
            "61/61 [==============================] - 28s 467ms/step - loss: 0.8976 - val_loss: 0.9980\n",
            "Epoch 36/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 0.8726 - val_loss: 0.9780\n",
            "Epoch 37/100\n",
            "61/61 [==============================] - 29s 470ms/step - loss: 0.8475 - val_loss: 0.9710\n",
            "Epoch 38/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.8369 - val_loss: 0.9623\n",
            "Epoch 39/100\n",
            "61/61 [==============================] - 29s 467ms/step - loss: 0.8090 - val_loss: 0.9542\n",
            "Epoch 40/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 0.7875 - val_loss: 0.9313\n",
            "Epoch 41/100\n",
            "61/61 [==============================] - 29s 470ms/step - loss: 0.7673 - val_loss: 0.9225\n",
            "Epoch 42/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.7480 - val_loss: 0.9179\n",
            "Epoch 43/100\n",
            "61/61 [==============================] - 28s 467ms/step - loss: 0.7295 - val_loss: 0.9056\n",
            "Epoch 44/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.7198 - val_loss: 0.9187\n",
            "Epoch 45/100\n",
            "61/61 [==============================] - 28s 467ms/step - loss: 0.6993 - val_loss: 0.9018\n",
            "Epoch 46/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.6836 - val_loss: 0.8758\n",
            "Epoch 47/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 0.6704 - val_loss: 0.8716\n",
            "Epoch 48/100\n",
            "61/61 [==============================] - 29s 469ms/step - loss: 0.6534 - val_loss: 0.9207\n",
            "Epoch 49/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.6410 - val_loss: 0.8544\n",
            "Epoch 50/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.6230 - val_loss: 0.8455\n",
            "Epoch 51/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.6136 - val_loss: 0.8461\n",
            "Epoch 52/100\n",
            "61/61 [==============================] - 29s 467ms/step - loss: 0.6024 - val_loss: 0.8411\n",
            "Epoch 53/100\n",
            "61/61 [==============================] - 29s 471ms/step - loss: 0.5878 - val_loss: 0.8352\n",
            "Epoch 54/100\n",
            "61/61 [==============================] - 29s 472ms/step - loss: 0.5823 - val_loss: 0.8206\n",
            "Epoch 55/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 0.5685 - val_loss: 0.8144\n",
            "Epoch 56/100\n",
            "61/61 [==============================] - 29s 467ms/step - loss: 0.5546 - val_loss: 0.8108\n",
            "Epoch 57/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.5449 - val_loss: 0.8079\n",
            "Epoch 58/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.5336 - val_loss: 0.8034\n",
            "Epoch 59/100\n",
            "61/61 [==============================] - 29s 468ms/step - loss: 0.5381 - val_loss: 0.8114\n",
            "Epoch 60/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.5150 - val_loss: 0.7911\n",
            "Epoch 61/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 0.5140 - val_loss: 0.7911\n",
            "Epoch 62/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 0.5151 - val_loss: 0.8458\n",
            "Epoch 63/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 0.4949 - val_loss: 0.7870\n",
            "Epoch 64/100\n",
            "61/61 [==============================] - 28s 462ms/step - loss: 0.4793 - val_loss: 0.7784\n",
            "Epoch 65/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 0.4722 - val_loss: 0.7767\n",
            "Epoch 66/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.4688 - val_loss: 0.7714\n",
            "Epoch 67/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.4585 - val_loss: 0.7715\n",
            "Epoch 68/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.4534 - val_loss: 0.7681\n",
            "Epoch 69/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 0.4405 - val_loss: 0.7679\n",
            "Epoch 70/100\n",
            "61/61 [==============================] - 29s 469ms/step - loss: 0.4315 - val_loss: 0.7653\n",
            "Epoch 71/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.4258 - val_loss: 0.7718\n",
            "Epoch 72/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 0.4194 - val_loss: 0.7598\n",
            "Epoch 73/100\n",
            "61/61 [==============================] - 28s 467ms/step - loss: 0.4321 - val_loss: 0.7633\n",
            "Epoch 74/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 0.4060 - val_loss: 0.7580\n",
            "Epoch 75/100\n",
            "61/61 [==============================] - 28s 467ms/step - loss: 0.4066 - val_loss: 0.7534\n",
            "Epoch 76/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 0.3993 - val_loss: 0.7523\n",
            "Epoch 77/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 0.3943 - val_loss: 0.7526\n",
            "Epoch 78/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 0.3843 - val_loss: 0.7606\n",
            "Epoch 79/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 0.3807 - val_loss: 0.7442\n",
            "Epoch 80/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.3742 - val_loss: 0.7578\n",
            "Epoch 81/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.3927 - val_loss: 0.7410\n",
            "Epoch 82/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.3595 - val_loss: 0.7479\n",
            "Epoch 83/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 0.3588 - val_loss: 0.7418\n",
            "Epoch 84/100\n",
            "61/61 [==============================] - 28s 466ms/step - loss: 0.3543 - val_loss: 0.7418\n",
            "Epoch 85/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.3567 - val_loss: 0.7382\n",
            "Epoch 86/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 0.3416 - val_loss: 0.7370\n",
            "Epoch 87/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 0.3433 - val_loss: 0.7531\n",
            "Epoch 88/100\n",
            "61/61 [==============================] - 28s 463ms/step - loss: 0.3384 - val_loss: 0.7882\n",
            "Epoch 89/100\n",
            "61/61 [==============================] - 28s 464ms/step - loss: 0.3315 - val_loss: 0.7375\n",
            "Epoch 90/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.3287 - val_loss: 0.7297\n",
            "Epoch 91/100\n",
            "61/61 [==============================] - 28s 465ms/step - loss: 0.3200 - val_loss: 0.7386\n",
            "Epoch 92/100\n",
            "61/61 [==============================] - 28s 468ms/step - loss: 0.3180 - val_loss: 0.7397\n",
            "Epoch 93/100\n",
            "61/61 [==============================] - 29s 469ms/step - loss: 0.3156 - val_loss: 0.7363\n",
            "Epoch 94/100\n",
            "61/61 [==============================] - 29s 468ms/step - loss: 0.3145 - val_loss: 0.7352\n",
            "Epoch 95/100\n",
            "61/61 [==============================] - 29s 474ms/step - loss: 0.3087 - val_loss: 0.7307\n",
            "Epoch 96/100\n",
            "61/61 [==============================] - 29s 474ms/step - loss: 0.3019 - val_loss: 0.7296\n",
            "Epoch 97/100\n",
            "61/61 [==============================] - 29s 475ms/step - loss: 0.3055 - val_loss: 0.7447\n",
            "Epoch 98/100\n",
            "61/61 [==============================] - 29s 471ms/step - loss: 0.3002 - val_loss: 0.7333\n",
            "Epoch 99/100\n",
            "61/61 [==============================] - 29s 474ms/step - loss: 0.2976 - val_loss: 0.7306\n",
            "Epoch 100/100\n",
            "61/61 [==============================] - 29s 472ms/step - loss: 0.2878 - val_loss: 0.7293\n",
            "Model: \"encoder_decoder_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_8 (Encoder)         multiple                  1174748   \n",
            "                                                                 \n",
            " decoder_12 (Decoder)        multiple                  2502044   \n",
            "                                                                 \n",
            " dense_62 (Dense)            multiple                  0 (unused)\n",
            "                                                                 \n",
            " embedding_layer_encoder (Em  multiple                 0 (unused)\n",
            " bedding)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,676,792\n",
            "Trainable params: 3,676,792\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(f,i ,attention):\n",
        "  i = i.split(\" \")\n",
        "  f = f.split() + ['[END]']\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  attention = attention[:len(f),:len(i)]\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "  fontdict = {'fontsize': 14}\n",
        "  ax.set_xticklabels([''] + i, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + f, fontdict=fontdict)\n",
        "\n",
        "\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')"
      ],
      "metadata": {
        "id": "27H9DDLO1kKF"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  \n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  attention_plot = np.zeros((40,40))\n",
        "  input_sequences = tknizer_err.texts_to_sequences([input_sentence])\n",
        "  encoder_sequence = pad_sequences(input_sequences, maxlen = 40, dtype='int32', padding='post')\n",
        "  encoder_output,state_h,state_c= model.layers[0](encoder_sequence,model.layers[0].initialize_states(1))\n",
        "  dec_input = tknizer_corb.word_index['<start>']\n",
        "  dec_input = (np.array(dec_input)).reshape(1,1)\n",
        "  states = [state_h,state_c]\n",
        "  j = 0\n",
        "  final = []\n",
        "  while j!=40:\n",
        "    predicted_out,state_h,state_c,attention_weights,context_vector=model.layers[1].onestepdecoder(dec_input,encoder_output,state_h,state_c)\n",
        "    #att_w.append(state_c)\n",
        "    \n",
        "    attention_weights = tf.reshape(attention_weights,(-1,))\n",
        "    attention_plot[j] = attention_weights.numpy()\n",
        "    #______________________________________\n",
        "\n",
        "    output = predicted_out\n",
        "    states = [state_h,state_c] #automatically get updated as above\n",
        "    output= tf.argmax(output[0]).numpy()\n",
        "    #print(output)\n",
        "    b = get_key(output)\n",
        "    if b == '<end>':\n",
        "      break\n",
        "    else:\n",
        "      final.append(get_key(output))\n",
        "      dec_input =tf.expand_dims([output], 0)\n",
        "      j+=1\n",
        " # plot_attention(att_w,input_sentence,final)\n",
        "  \n",
        "  return ' '.join(final),input_sentence,attention_plot"
      ],
      "metadata": {
        "id": "rSTP0NskD7U6"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_key(val):\n",
        "    for key, value in tknizer_cor.word_index.items():\n",
        "         if val == value:\n",
        "             return key\n",
        " \n",
        "    return \"key doesn't exist\""
      ],
      "metadata": {
        "id": "N4j50iZ8139z"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(10,15):\n",
        "  f,i,at  =  predict(validation.iloc[j][0])\n",
        "  print('Orignal Corrupted : ',validation.iloc[j][0])\n",
        "  print('Orignal  Uncorrupted : ',validation.iloc[j][1])\n",
        "  print('Predicted Corrected: ',f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXC_de4o1nQz",
        "outputId": "f898f251-5aa4-4a58-a0b6-6f2741266047"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orignal Corrupted :  hellow \n",
            "Orignal  Uncorrupted :  <start> hellow \n",
            "Predicted Corrected:  hello\n",
            "Orignal Corrupted :  when my hair will cure  i dye them again \n",
            "Orignal  Uncorrupted :  <start> when my hair is cured  i  will dye it again \n",
            "Predicted Corrected:  when my hair will\n",
            "Orignal Corrupted :  do  not be afraid to ask me for help  \n",
            "Orignal  Uncorrupted :  <start> do  not be afraid to ask me for help  \n",
            "Predicted Corrected:  do not be afraid to ask me for help for help for help for help for help for help for help for help for help for help for help for help for help for help for help for help for\n",
            "Orignal Corrupted :  i have finished scenario mode  normal  and challenge mode \n",
            "Orignal  Uncorrupted :  <start> i have finished scenario mode  normal  and challenge mode \n",
            "Predicted Corrected:  i have finished frustrated the japanese and the challenge meat charles challenge meat\n",
            "Orignal Corrupted :  many sports company buildings and a lot of small shops \n",
            "Orignal  Uncorrupted :  <start> there were many sports company buildings and a lot of small shops \n",
            "Predicted Corrected:  many sports company requires and a lot of small shops that a lot of small shops that a lot of small shops that a lot of small shops that a lot of small shops that a lot of small shops\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "dFgXKCL22g3j",
        "outputId": "0c1850a5-0bf1-4279-ff01-16077f459914"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final = []\n",
        "orignal = []\n",
        "for i in range(len(validation)):#overworks himself '-'\n",
        "  f,i,a = (predict(validation.iloc[i][0]))\n",
        "  final.append(f)\n",
        "orignal = []\n",
        "for i in range(len(validation)):\n",
        "  #print(i)\n",
        "  orignal.append((validation.iloc[i][1])[8:])\n",
        "#bleu_Score"
      ],
      "metadata": {
        "id": "oFERyY_-2hNS"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from __future__ import division"
      ],
      "metadata": {
        "id": "7DzIyh_t2kpq"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "bleu_avg = []\n",
        "\n",
        "for i in range(len(final)):\n",
        "  hypothesis = final[i].split()\n",
        "  reference = orignal[i].split()\n",
        "  #there may be several references\n",
        "  BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis)\n",
        "  bleu_avg.append(BLEUscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTlg3TSZ2mOq",
        "outputId": "b8bf23e4-ce46-43b6-98ef-ab4e0441254b"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Bleu Score for concat :',sum(bleu_avg)/len(bleu_avg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oZZKABC2nei",
        "outputId": "dcf35fb7-769f-4cc1-c7c9-a1c88b0f8304"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Bleu Score for concat : 0.4957232120278114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GedIesgk2o9q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Untitled66.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}